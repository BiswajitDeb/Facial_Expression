{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import imghdr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Affectnet Dataset'\n",
    "data=pd.read_csv('Affectnet Dataset\\labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['pth'].values\n",
    "y = data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "test_img=cv2.imread('Affectnet Dataset/anger/image0000006.jpg')\n",
    "#type(test_img)\n",
    "# test_img.flatten()/255\n",
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import cv2\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(data_dir+\"/\"+image_path)    \n",
    "    img_normalized = img / 255\n",
    "    return img_normalized\n",
    "\n",
    "# for image_path in X:\n",
    "#     X_preprocessed=np.append(preprocess_image)\n",
    "X_preprocessed=np.array([preprocess_image(image_path) for image_path in X])\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_preprocessed = to_categorical(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_preprocessed=np.array([preprocess_image(image_path) for image_path in X])\n",
    "# data_dir='Affectnet Dataset'\n",
    "# X_preprocessed=[]\n",
    "\n",
    "# for image_path in X:\n",
    "#     img = cv2.imread(data_dir+\"/\"+image_path)    \n",
    "#     img_normalized = img/255.0\n",
    "#     X_preprocessed.append(img_normalized)\n",
    "#     # \n",
    "\n",
    "\n",
    "# X_preprocessed=np.array(X_preprocessed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting Test train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y_preprocessed, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Deep learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), 1, activation='relu', input_shape=(256,256,3)))#Convolution layer 1\n",
    "model.add(Conv2D(128, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))#Pooling layer 1\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3,3), 1, activation='relu'))#Convolution layer 2\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))#Pooling layer 2\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))#Convolution layer 3\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))#Pooling layer 3\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())#Fully Connected layer\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))#Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer='sgd',\n",
    "#               metrics=[metrics.mae,\n",
    "#                        metrics.categorical_accuracy])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "          loss='categorical_crossentropy', \n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile('sgd', loss=tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model).show() # display using your system viewer\n",
    "visualkeras.layered_view(model, to_file='Neural_Network_Visualize.png') # write to disk\n",
    "visualkeras.layered_view(model, to_file='Neural_Network_Visualize.png').show() # write and show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_history = model.fit(X_train,y_train, epochs=10, batch_size=64,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/emotion_latest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(Log_history.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping={0: 'anger',\n",
    " 1: 'contempt',\n",
    " 2: 'disgust',\n",
    " 3: 'fear',\n",
    " 4: 'happy',\n",
    " 5: 'neutral',\n",
    " 6: 'sad',\n",
    " 7: 'surprise'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred_prob=model.predict(X_test)\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred_labels = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to binary labels\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# List to store individual precision, recall, and F1-score values for each class\n",
    "class_metrics = []\n",
    "\n",
    "# List to store individual AUC values and ROC curves for each class\n",
    "roc_curves = []\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "    # Convert predicted and true labels to binary labels\n",
    "    y_pred_binary = (y_pred_labels == i)\n",
    "    y_true_binary = (y_true_labels == i)\n",
    "    \n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(y_true_binary, y_pred_binary)\n",
    "    recall = recall_score(y_true_binary, y_pred_binary)\n",
    "    f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "    \n",
    "    # ROC curve calculation\n",
    "    fpr, tpr, _ = roc_curve(y_true_binary, y_pred_prob[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_curves.append((fpr, tpr, label_mapping[i]))\n",
    "    \n",
    "    # Store metrics in a dictionary\n",
    "    class_metrics.append({\n",
    "        'Label': label_mapping[i],\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1,\n",
    "        'AUC': roc_auc\n",
    "    })\n",
    "\n",
    "\n",
    "    \n",
    "# Compute and plot macro-average ROC curve\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = np.mean([np.interp(mean_fpr, fpr, tpr) for fpr, tpr, _ in roc_curves], axis=0)\n",
    "macro_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate overall precision, recall, and F1-score\n",
    "overall_precision = precision_score(y_true_labels, y_pred_labels, average='macro')\n",
    "overall_recall = recall_score(y_true_labels, y_pred_labels, average='macro')\n",
    "overall_f1 = f1_score(y_true_labels, y_pred_labels, average='macro')\n",
    "\n",
    "class_metrics.append({\n",
    "    'Label': 'Overall',\n",
    "    'Precision': overall_precision,\n",
    "    'Recall': overall_recall,\n",
    "    'F1-score': overall_f1,\n",
    "    'AUC': macro_auc\n",
    "})\n",
    "\n",
    "\n",
    "# Create a Pandas DataFrame from the list of metrics\n",
    "metrics_df = pd.DataFrame(class_metrics)\n",
    "\n",
    "# Optionally, print the metrics table\n",
    "print(metrics_df)\n",
    "\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(12, 8))\n",
    "lw = 2\n",
    "\n",
    "    \n",
    "for fpr, tpr, label in roc_curves:\n",
    "    plt.plot(fpr, tpr, lw=lw, label='ROC curve (area = {:.2f}) for Emotion: {}'.format(roc_auc, label))\n",
    "\n",
    "plt.plot(mean_fpr, mean_tpr, color='darkorange', linestyle='--', linewidth=2, label='Macro-average ROC curve (area = {:.2f})'.format(macro_auc))\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic for Each Class')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall,BinaryAccuracy,categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()\n",
    "cat_acc = categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y =batch\n",
    "yhat=model.predict(X)\n",
    "print(cat_acc(y,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)\n",
    "    cat_acc(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cat_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision:{pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy : {acc.result().numpy()},Categorical_Accuracy : {cat_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test/happy.jpg')\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(resize,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yhat > 0.5: \n",
    "    print(f'Predicted class is Sad')\n",
    "else:\n",
    "    print(f'Predicted class is Happy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','emotion_cnn.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model(os.path.join('models','emotion_cnn.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.predict(np.expand_dims(resize/255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
