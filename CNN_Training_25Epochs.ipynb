{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_14928\\3925996245.py:6: DeprecationWarning: 'imghdr' is deprecated and slated for removal in Python 3.13\n",
      "  import imghdr\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import imghdr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_14928\\3271766593.py:2: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  data=pd.read_csv('Affectnet Dataset\\labels.csv')\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'Affectnet Dataset'\n",
    "data=pd.read_csv('Affectnet Dataset\\labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pth</th>\n",
       "      <th>label</th>\n",
       "      <th>relFCs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>anger/image0000006.jpg</td>\n",
       "      <td>surprise</td>\n",
       "      <td>0.873142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>anger/image0000060.jpg</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.852311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>anger/image0000061.jpg</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.800957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>anger/image0000066.jpg</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.843079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>anger/image0000106.jpg</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.849108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     pth     label    relFCs\n",
       "0           0  anger/image0000006.jpg  surprise  0.873142\n",
       "1           1  anger/image0000060.jpg     anger  0.852311\n",
       "2           2  anger/image0000061.jpg     anger  0.800957\n",
       "3           3  anger/image0000066.jpg   disgust  0.843079\n",
       "4           4  anger/image0000106.jpg     anger  0.849108"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['pth'].values\n",
    "y = data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger/image0000006.jpg', 'anger/image0000060.jpg',\n",
       "       'anger/image0000061.jpg', ..., 'surprise/image0034966.jpg',\n",
       "       'surprise/image0034973.jpg', 'surprise/image0042075.jpg'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''img = cv2.imread(data_dir+\"/\"+X[4]) \n",
    "#img = cv2.imread(data_dir+\"/\"+image_path) \n",
    "clf = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    #faces contains coordinates of the face\n",
    "faces = clf.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "print(f'Faces : {faces}\\n')\n",
    "    \n",
    "input_image = cv2.cvtColor(img[faces[0][1]:(faces[0][1]+faces[0][3]),faces[0][0]:(faces[0][0]+faces[0][3])],cv2.COLOR_BGR2RGB)   '''\n",
    "    \n",
    "#input_image = cv2.cvtColor(img[faces[0][1]:(faces[0][1]+faces[0][3]),faces[0][0]:(faces[0][0]+faces[0][3])],cv2.COLOR_BGR2RGB)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28175\n"
     ]
    }
   ],
   "source": [
    "print(X.size)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import cv2\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(data_dir+\"/\"+image_path) \n",
    "    clf = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    #faces contains coordinates of the face\n",
    "    faces = clf.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    #print(f'Faces : {faces}\\n')\n",
    "    \n",
    "    input_image = cv2.cvtColor(img[faces[0][1]:(faces[0][1]+faces[0][3]),faces[0][0]:(faces[0][0]+faces[0][3])],cv2.COLOR_BGR2RGB)   \n",
    "    img_normalized = input_image / 255.0\n",
    "    return img_normalized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "anger/image0000006.jpg\n",
      "2\n",
      "anger/image0000060.jpg\n",
      "3\n",
      "anger/image0000061.jpg\n",
      "4\n",
      "anger/image0000066.jpg\n",
      "5\n",
      "anger/image0000106.jpg\n",
      "6\n",
      "anger/image0000132.jpg\n",
      "7\n",
      "anger/image0000138.jpg\n",
      "8\n",
      "anger/image0000182.jpg\n",
      "9\n",
      "anger/image0000195.jpg\n",
      "10\n",
      "anger/image0000213.jpg\n",
      "11\n",
      "anger/image0000228.jpg\n",
      "12\n",
      "anger/image0000294.jpg\n",
      "13\n",
      "anger/image0000333.jpg\n",
      "14\n",
      "anger/image0000343.jpg\n",
      "15\n",
      "anger/image0000346.jpg\n",
      "16\n",
      "anger/image0000356.jpg\n",
      "17\n",
      "anger/image0000368.jpg\n",
      "18\n",
      "anger/image0000374.jpg\n",
      "19\n",
      "anger/image0000390.jpg\n",
      "20\n",
      "anger/image0000399.jpg\n",
      "21\n",
      "anger/image0000407.jpg\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(count)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(image_path)\n\u001b[1;32m----> 7\u001b[0m     X_preprocessed\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#X_preprocessed=np.array([preprocess_image(image_path) for image_path in X])\u001b[39;00m\n\u001b[0;32m      9\u001b[0m X_preprocessed\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(X_preprocessed)\n",
      "Cell \u001b[1;32mIn[11], line 12\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m faces \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mdetectMultiScale(img, scaleFactor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.1\u001b[39m, minNeighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, minSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m30\u001b[39m))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#print(f'Faces : {faces}\\n')\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m input_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img[\u001b[43mfaces\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m1\u001b[39m]:(faces[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mfaces[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m]),faces[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]:(faces[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mfaces[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m])],cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)   \n\u001b[0;32m     13\u001b[0m img_normalized \u001b[38;5;241m=\u001b[39m input_image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img_normalized\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "X_preprocessed=[]\n",
    "count=0\n",
    "for image_path in X:\n",
    "    count+=1\n",
    "    print(count)\n",
    "    print(image_path)\n",
    "    X_preprocessed.append(preprocess_image(image_path))\n",
    "#X_preprocessed=np.array([preprocess_image(image_path) for image_path in X])\n",
    "X_preprocessed=np.array(X_preprocessed)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_preprocessed = to_categorical(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_preprocessed=np.array([preprocess_image(image_path) for image_path in X])\n",
    "# data_dir='Affectnet Dataset'\n",
    "# X_preprocessed=[]\n",
    "\n",
    "# for image_path in X:\n",
    "#     img = cv2.imread(data_dir+\"/\"+image_path)    \n",
    "#     img_normalized = img/255.0\n",
    "#     X_preprocessed.append(img_normalized)\n",
    "#     # \n",
    "\n",
    "\n",
    "# X_preprocessed=np.array(X_preprocessed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting Test train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y_preprocessed, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Deep learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), 1, activation='relu', input_shape=(96,96,3)))#Convolution layer 1\n",
    "model.add(Conv2D(128, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))#Pooling layer 1\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3,3), 1, activation='relu'))#Convolution layer 2\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))#Pooling layer 2\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))#Convolution layer 3\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))#Pooling layer 3\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())#Fully Connected layer\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))#Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer='sgd',\n",
    "#               metrics=[metrics.mae,\n",
    "#                        metrics.categorical_accuracy])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "          loss='categorical_crossentropy', \n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile('sgd', loss=tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model).show() # display using your system viewer\n",
    "visualkeras.layered_view(model, to_file='Neural_Network_Visualize.png') # write to disk\n",
    "visualkeras.layered_view(model, to_file='Neural_Network_Visualize.png').show() # write and show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_history = model.fit(X_train,y_train, epochs=25, batch_size=64,validation_split=0.2,callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/emotion_latest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(Log_history.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping={0: 'anger',\n",
    " 1: 'contempt',\n",
    " 2: 'disgust',\n",
    " 3: 'fear',\n",
    " 4: 'happy',\n",
    " 5: 'neutral',\n",
    " 6: 'sad',\n",
    " 7: 'surprise'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred_prob=model.predict(X_test)\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred_labels = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to binary labels\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# List to store individual precision, recall, and F1-score values for each class\n",
    "class_metrics = []\n",
    "\n",
    "# List to store individual AUC values and ROC curves for each class\n",
    "roc_curves = []\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "    # Convert predicted and true labels to binary labels\n",
    "    y_pred_binary = (y_pred_labels == i)\n",
    "    y_true_binary = (y_true_labels == i)\n",
    "    \n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(y_true_binary, y_pred_binary)\n",
    "    recall = recall_score(y_true_binary, y_pred_binary)\n",
    "    f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "    \n",
    "    # ROC curve calculation\n",
    "    fpr, tpr, _ = roc_curve(y_true_binary, y_pred_prob[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_curves.append((fpr, tpr, label_mapping[i]))\n",
    "    \n",
    "    # Store metrics in a dictionary\n",
    "    class_metrics.append({\n",
    "        'Label': label_mapping[i],\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1,\n",
    "        'AUC': roc_auc\n",
    "    })\n",
    "\n",
    "\n",
    "    \n",
    "# Compute and plot macro-average ROC curve\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = np.mean([np.interp(mean_fpr, fpr, tpr) for fpr, tpr, _ in roc_curves], axis=0)\n",
    "macro_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate overall precision, recall, and F1-score\n",
    "overall_precision = precision_score(y_true_labels, y_pred_labels, average='macro')\n",
    "overall_recall = recall_score(y_true_labels, y_pred_labels, average='macro')\n",
    "overall_f1 = f1_score(y_true_labels, y_pred_labels, average='macro')\n",
    "\n",
    "class_metrics.append({\n",
    "    'Label': 'Overall',\n",
    "    'Precision': overall_precision,\n",
    "    'Recall': overall_recall,\n",
    "    'F1-score': overall_f1,\n",
    "    'AUC': macro_auc\n",
    "})\n",
    "\n",
    "\n",
    "# Create a Pandas DataFrame from the list of metrics\n",
    "metrics_df = pd.DataFrame(class_metrics)\n",
    "\n",
    "# Optionally, print the metrics table\n",
    "print(metrics_df)\n",
    "\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(12, 8))\n",
    "lw = 2\n",
    "\n",
    "    \n",
    "for fpr, tpr, label in roc_curves:\n",
    "    plt.plot(fpr, tpr, lw=lw, label='ROC curve (area = {:.2f}) for Emotion: {}'.format(roc_auc, label))\n",
    "\n",
    "plt.plot(mean_fpr, mean_tpr, color='darkorange', linestyle='--', linewidth=2, label='Macro-average ROC curve (area = {:.2f})'.format(macro_auc))\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic for Each Class')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test/happy.jpg')\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (96,96))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(resize,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_result = np.argmax(yhat)\n",
    "classify_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping={0: 'anger',\n",
    " 1: 'contempt',\n",
    " 2: 'disgust',\n",
    " 3: 'fear',\n",
    " 4: 'happy',\n",
    " 5: 'neutral',\n",
    " 6: 'sad',\n",
    " 7: 'surprise'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','Final_CNN_with25epochs.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model(os.path.join('models','Final_CNN_with25epochs.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.predict(np.expand_dims(resize/255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(resize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
