{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Biswaji Deb\\AppData\\Local\\Temp\\ipykernel_5372\\3925996245.py:6: DeprecationWarning: 'imghdr' is deprecated and slated for removal in Python 3.13\n",
      "  import imghdr\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import imghdr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Affectnet Dataset'\n",
    "data=pd.read_csv('Affectnet Dataset\\labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pth</th>\n",
       "      <th>label</th>\n",
       "      <th>relFCs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>anger/image0000006.jpg</td>\n",
       "      <td>surprise</td>\n",
       "      <td>0.873142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>anger/image0000060.jpg</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.852311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>anger/image0000061.jpg</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.800957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>anger/image0000066.jpg</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.843079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>anger/image0000106.jpg</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.849108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     pth     label    relFCs\n",
       "0           0  anger/image0000006.jpg  surprise  0.873142\n",
       "1           1  anger/image0000060.jpg     anger  0.852311\n",
       "2           2  anger/image0000061.jpg     anger  0.800957\n",
       "3           3  anger/image0000066.jpg   disgust  0.843079\n",
       "4           4  anger/image0000106.jpg     anger  0.849108"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28175 entries, 0 to 28174\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  28175 non-null  int64  \n",
      " 1   pth         28175 non-null  object \n",
      " 2   label       28175 non-null  object \n",
      " 3   relFCs      28175 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 880.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['pth'].values\n",
    "y = data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger/image0000006.jpg', 'anger/image0000060.jpg',\n",
       "       'anger/image0000061.jpg', ..., 'surprise/image0034966.jpg',\n",
       "       'surprise/image0034973.jpg', 'surprise/image0042075.jpg'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces : [[ 9  7 81 81]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(data_dir+\"/\"+X[4]) \n",
    "#img = cv2.imread(data_dir+\"/\"+image_path) \n",
    "clf = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    #faces contains coordinates of the face\n",
    "faces = clf.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "print(f'Faces : {faces}\\n')\n",
    "    \n",
    "input_image = cv2.cvtColor(img[faces[0][1]:(faces[0][1]+faces[0][3]),faces[0][0]:(faces[0][0]+faces[0][3])],cv2.COLOR_BGR2RGB)   \n",
    "    \n",
    "#input_image = cv2.cvtColor(img[faces[0][1]:(faces[0][1]+faces[0][3]),faces[0][0]:(faces[0][0]+faces[0][3])],cv2.COLOR_BGR2RGB)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces : [[10 10 77 77]]\n",
      "\n",
      "Faces : [[12 11 73 73]]\n",
      "\n",
      "Faces : [[10 12 74 74]]\n",
      "\n",
      "Faces : [[13 12 72 72]]\n",
      "\n",
      "Faces : [[ 9  7 81 81]]\n",
      "\n",
      "Faces : [[13 13 70 70]]\n",
      "\n",
      "Faces : [[10 10 76 76]]\n",
      "\n",
      "Faces : [[17 15 64 64]]\n",
      "\n",
      "Faces : [[13 13 71 71]]\n",
      "\n",
      "Faces : [[13 10 78 78]]\n",
      "\n",
      "Faces : [[11 13 73 73]]\n",
      "\n",
      "Faces : [[11 13 75 75]]\n",
      "\n",
      "Faces : [[12 11 73 73]]\n",
      "\n",
      "Faces : [[11 11 75 75]]\n",
      "\n",
      "Faces : [[13 13 72 72]]\n",
      "\n",
      "Faces : [[ 5  5 85 85]]\n",
      "\n",
      "Faces : [[ 7  7 84 84]]\n",
      "\n",
      "Faces : [[ 9  6 81 81]]\n",
      "\n",
      "Faces : [[ 9 11 77 77]]\n",
      "\n",
      "Faces : [[14 13 71 71]]\n",
      "\n",
      "Faces : ()\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img_normalized\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# for image_path in X:\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#     X_preprocessed=np.append(preprocess_image)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m X_preprocessed\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     21\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m     22\u001b[0m y_preprocessed \u001b[38;5;241m=\u001b[39m to_categorical(le\u001b[38;5;241m.\u001b[39mfit_transform(y))\n",
      "Cell \u001b[1;32mIn[40], line 18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img_normalized\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# for image_path in X:\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#     X_preprocessed=np.append(preprocess_image)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m X_preprocessed\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m X])\n\u001b[0;32m     21\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m     22\u001b[0m y_preprocessed \u001b[38;5;241m=\u001b[39m to_categorical(le\u001b[38;5;241m.\u001b[39mfit_transform(y))\n",
      "Cell \u001b[1;32mIn[40], line 12\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m faces \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mdetectMultiScale(img, scaleFactor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.1\u001b[39m, minNeighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, minSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m30\u001b[39m))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFaces : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfaces\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m input_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img[\u001b[43mfaces\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m1\u001b[39m]:(faces[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mfaces[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m]),faces[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]:(faces[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mfaces[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m])],cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)   \n\u001b[0;32m     13\u001b[0m img_normalized \u001b[38;5;241m=\u001b[39m input_image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img_normalized\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import cv2\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(data_dir+\"/\"+image_path) \n",
    "    clf = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    #faces contains coordinates of the face\n",
    "    faces = clf.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    print(f'Faces : {faces}\\n')\n",
    "    \n",
    "    input_image = cv2.cvtColor(img[faces[0][1]:(faces[0][1]+faces[0][3]),faces[0][0]:(faces[0][0]+faces[0][3])],cv2.COLOR_BGR2RGB)   \n",
    "    img_normalized = input_image / 255.0\n",
    "    return img_normalized\n",
    "\n",
    "# for image_path in X:\n",
    "#     X_preprocessed=np.append(preprocess_image)\n",
    "X_preprocessed=np.array([preprocess_image(image_path) for image_path in X])\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_preprocessed = to_categorical(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_preprocessed=np.array([preprocess_image(image_path) for image_path in X])\n",
    "# data_dir='Affectnet Dataset'\n",
    "# X_preprocessed=[]\n",
    "\n",
    "# for image_path in X:\n",
    "#     img = cv2.imread(data_dir+\"/\"+image_path)    \n",
    "#     img_normalized = img/255.0\n",
    "#     X_preprocessed.append(img_normalized)\n",
    "#     # \n",
    "\n",
    "\n",
    "# X_preprocessed=np.array(X_preprocessed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting Test train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y_preprocessed, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Deep learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), 1, activation='relu', input_shape=(96,96,3)))#Convolution layer 1\n",
    "model.add(Conv2D(128, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))#Pooling layer 1\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3,3), 1, activation='relu'))#Convolution layer 2\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))#Pooling layer 2\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))#Convolution layer 3\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))#Pooling layer 3\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())#Fully Connected layer\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))#Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer='sgd',\n",
    "#               metrics=[metrics.mae,\n",
    "#                        metrics.categorical_accuracy])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "          loss='categorical_crossentropy', \n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile('sgd', loss=tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model).show() # display using your system viewer\n",
    "visualkeras.layered_view(model, to_file='Neural_Network_Visualize.png') # write to disk\n",
    "visualkeras.layered_view(model, to_file='Neural_Network_Visualize.png').show() # write and show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_history = model.fit(X_train,y_train, epochs=25, batch_size=64,validation_split=0.2,callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/emotion_latest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(Log_history.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping={0: 'anger',\n",
    " 1: 'contempt',\n",
    " 2: 'disgust',\n",
    " 3: 'fear',\n",
    " 4: 'happy',\n",
    " 5: 'neutral',\n",
    " 6: 'sad',\n",
    " 7: 'surprise'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred_prob=model.predict(X_test)\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred_labels = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to binary labels\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# List to store individual precision, recall, and F1-score values for each class\n",
    "class_metrics = []\n",
    "\n",
    "# List to store individual AUC values and ROC curves for each class\n",
    "roc_curves = []\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "    # Convert predicted and true labels to binary labels\n",
    "    y_pred_binary = (y_pred_labels == i)\n",
    "    y_true_binary = (y_true_labels == i)\n",
    "    \n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(y_true_binary, y_pred_binary)\n",
    "    recall = recall_score(y_true_binary, y_pred_binary)\n",
    "    f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "    \n",
    "    # ROC curve calculation\n",
    "    fpr, tpr, _ = roc_curve(y_true_binary, y_pred_prob[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_curves.append((fpr, tpr, label_mapping[i]))\n",
    "    \n",
    "    # Store metrics in a dictionary\n",
    "    class_metrics.append({\n",
    "        'Label': label_mapping[i],\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1,\n",
    "        'AUC': roc_auc\n",
    "    })\n",
    "\n",
    "\n",
    "    \n",
    "# Compute and plot macro-average ROC curve\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = np.mean([np.interp(mean_fpr, fpr, tpr) for fpr, tpr, _ in roc_curves], axis=0)\n",
    "macro_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate overall precision, recall, and F1-score\n",
    "overall_precision = precision_score(y_true_labels, y_pred_labels, average='macro')\n",
    "overall_recall = recall_score(y_true_labels, y_pred_labels, average='macro')\n",
    "overall_f1 = f1_score(y_true_labels, y_pred_labels, average='macro')\n",
    "\n",
    "class_metrics.append({\n",
    "    'Label': 'Overall',\n",
    "    'Precision': overall_precision,\n",
    "    'Recall': overall_recall,\n",
    "    'F1-score': overall_f1,\n",
    "    'AUC': macro_auc\n",
    "})\n",
    "\n",
    "\n",
    "# Create a Pandas DataFrame from the list of metrics\n",
    "metrics_df = pd.DataFrame(class_metrics)\n",
    "\n",
    "# Optionally, print the metrics table\n",
    "print(metrics_df)\n",
    "\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(12, 8))\n",
    "lw = 2\n",
    "\n",
    "    \n",
    "for fpr, tpr, label in roc_curves:\n",
    "    plt.plot(fpr, tpr, lw=lw, label='ROC curve (area = {:.2f}) for Emotion: {}'.format(roc_auc, label))\n",
    "\n",
    "plt.plot(mean_fpr, mean_tpr, color='darkorange', linestyle='--', linewidth=2, label='Macro-average ROC curve (area = {:.2f})'.format(macro_auc))\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic for Each Class')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test/happy.jpg')\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (96,96))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(resize,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_result = np.argmax(yhat)\n",
    "classify_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping={0: 'anger',\n",
    " 1: 'contempt',\n",
    " 2: 'disgust',\n",
    " 3: 'fear',\n",
    " 4: 'happy',\n",
    " 5: 'neutral',\n",
    " 6: 'sad',\n",
    " 7: 'surprise'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','Final_CNN_with25epochs.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model(os.path.join('models','Final_CNN_with25epochs.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.predict(np.expand_dims(resize/255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(resize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
